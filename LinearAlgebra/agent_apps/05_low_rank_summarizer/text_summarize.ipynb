{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ca1ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Text Summarization with Latent Semantic Analysis (SVD)\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Tiny toy corpus\n",
    "docs = [\n",
    "    \"Linear algebra is essential for AI agents and machine learning.\",\n",
    "    \"Agents use vector similarity and matrix operations.\",\n",
    "    \"Singular value decomposition helps in summarization and topic extraction.\",\n",
    "    \"Matrix factorization is widely applied in recommendation systems.\"\n",
    "]\n",
    "\n",
    "# Step 1: Build term-document matrix\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(docs).toarray()\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"Term-Document Matrix:\\n\", X)\n",
    "\n",
    "# Step 2: Apply SVD\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "# Keep top k topics\n",
    "k = 2\n",
    "U_k = U[:, :k]\n",
    "S_k = np.diag(S[:k])\n",
    "Vt_k = Vt[:k, :]\n",
    "\n",
    "# Approx reconstruction\n",
    "Xk = U_k @ S_k @ Vt_k\n",
    "\n",
    "# Step 3: Sentence scores\n",
    "sentence_strength = np.linalg.norm(Xk, axis=1)\n",
    "ranked = np.argsort(-sentence_strength)\n",
    "\n",
    "# Select top 2 sentences as summary\n",
    "summary = [docs[i] for i in ranked[:2]]\n",
    "\n",
    "print(\"\\nSummary:\\n\", \"\\n\".join(summary))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
